{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas\n",
    "def read_data(dir_path):\n",
    "    examples = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if not filename.endswith(\"txt\"):\n",
    "            continue\n",
    "        keys = filename.split(\".\")[0].split(\"_\")\n",
    "        assert len(keys) == 3\n",
    "        # keys is [id, label, review_score]. For now we are only interested in the label\n",
    "        label = keys[1]\n",
    "        with open(os.path.join(dir_path, filename)) as f:\n",
    "            text = f.read().strip().replace(\"<br />\", \" \")\n",
    "        examples.append([text, 1 if label == 'pos' else 0])\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SIZE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's beyond my comprehension that so much rubb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'What I Like About You' is definitely a show t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELVIRA, MISTRESS OF THE DARK (1988)  directed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is one of the most spiritual movies I hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man With the Gun is pretty much forgotten now,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Police Story is one of Jackie Chan's classic f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>If you need cheering up on a cold weekday even...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>A wonderful early musical film from Rene Clair...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>A light-hearted comedy, Nothing shows us a wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>**Warning! Spoilers Ahead!**  This short is pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    It's beyond my comprehension that so much rubb...      1\n",
       "1    'What I Like About You' is definitely a show t...      1\n",
       "2    ELVIRA, MISTRESS OF THE DARK (1988)  directed ...      1\n",
       "3    This is one of the most spiritual movies I hav...      1\n",
       "4    Man With the Gun is pretty much forgotten now,...      1\n",
       "..                                                 ...    ...\n",
       "795  Police Story is one of Jackie Chan's classic f...      1\n",
       "796  If you need cheering up on a cold weekday even...      1\n",
       "797  A wonderful early musical film from Rene Clair...      1\n",
       "798  A light-hearted comedy, Nothing shows us a wor...      1\n",
       "799  **Warning! Spoilers Ahead!**  This short is pa...      1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SDEV_DIR = '../imdb-data/sd{}'.format(DEV_SIZE)\n",
    "sdev_data = read_data(SDEV_DIR)\n",
    "sdev_df = pd.DataFrame(sdev_data, columns=['text', 'label'])\n",
    "sdev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to start saying it has been a long time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought that Mukhsin has been wonderfully wr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all this was not a three hour movie -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I cant understand at all why so many Godzilla ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Hatred of a Minute\" is arguably one of the be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>I agree with other users comments in that the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This movie is about this wimpy guy who decides...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I really enjoyed The 60's. Not being of that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>While on a vacation at the beach, red-haired b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I saw \"El Mar\" yesterday and thought it to be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24016 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I have to start saying it has been a long time...      1\n",
       "1      I thought that Mukhsin has been wonderfully wr...      1\n",
       "2      First of all this was not a three hour movie -...      1\n",
       "3      I cant understand at all why so many Godzilla ...      0\n",
       "5      \"Hatred of a Minute\" is arguably one of the be...      1\n",
       "...                                                  ...    ...\n",
       "24994  I agree with other users comments in that the ...      0\n",
       "24995  This movie is about this wimpy guy who decides...      1\n",
       "24997  I really enjoyed The 60's. Not being of that g...      1\n",
       "24998  While on a vacation at the beach, red-haired b...      0\n",
       "24999  I saw \"El Mar\" yesterday and thought it to be ...      1\n",
       "\n",
       "[24016 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_DIR = '../imdb-data/og'\n",
    "train_data = read_data(TRAIN_DIR)\n",
    "\n",
    "all_train_df = pd.DataFrame(train_data, columns=['text', 'label'])\n",
    "train_df = pd.concat([all_train_df, sdev_df]).drop_duplicates(keep=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most indicative words using Naive Bayes on sdevset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  3064\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.imdb import return_keywords_indices\n",
    "\n",
    "all_words, most_pos_indices, most_neg_indices = return_keywords_indices(sdev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_KEYWORDS = 50\n",
    "\n",
    "top_pos_words = [all_words[ind] for ind in most_pos_indices[:NUM_KEYWORDS]]\n",
    "top_neg_words = [all_words[ind] for ind in most_neg_indices[:NUM_KEYWORDS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top pos words:\n",
      "['eddie', 'jackie', 'everyday', 'douglas', 'cold', 'stands', 'ned', 'wonderful', 'spy', 'built', 'wonderfully', 'wall', 'daniel', 'finest', 'thrillers', 'gorgeous', 'delightful', 'professional', 'lonely', 'genuine', 'captures', 'saturday', 'glory', 'adapted', 'counter', 'captivating', 'california', 'develops', 'lucky', 'strength', 'studios', 'uncut', 'quiet', 'stunning', 'paris', 'flight', 'gordon', 'underground', 'builds', 'brilliantly', 'captured', 'mrs', 'covered', 'portrait', 'delight', 'lovers', 'critical', 'intensity', 'melodrama', 'sentimental']\n",
      "\n",
      "Top neg words:\n",
      "['terrible', 'disappointing', 'waste', 'lowbudget', '310', 'darkness', 'villains', 'disappointment', 'nonexistent', 'ridiculous', 'pointless', 'joe', 'mess', 'ape', 'horrendous', 'forgettable', 'juvenile', 'garbage', 'amateur', 'incomprehensible', 'remotely', 'toilet', 'zero', 'offended', 'gotta', 'unwatchable', 'realized', 'unintentional', 'outer', 'cheated', 'wasted', 'atrocious', 'ugly', 'promise', 'tarzan', 'awful', 'jane', 'looked', 'law', 'worst', 'pretentious', 'subjected', 'secondly', 'amazed', 'blatantly', 'riding', 'employed', 'woody', 'plague', 'incoherent']\n"
     ]
    }
   ],
   "source": [
    "print('Top pos words:')\n",
    "print(top_pos_words)\n",
    "print('\\nTop neg words:')\n",
    "print(top_neg_words)\n",
    "\n",
    "# Remember to post-process these by removing those words that are correlational but not causal, e.g. 'germany'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = set(['eddie', 'jackie', 'everyday', 'douglas', 'cold', \n",
    "                 'stands', 'ned', 'wonderful', 'spy', 'built', \n",
    "                 'wonderfully', 'wall', 'daniel', 'finest', 'thrillers',\n",
    "                 'gorgeous', 'delightful', 'professional', 'lonely', 'genuine',\n",
    "                 'captures', 'saturday', 'glory', 'adapted', 'counter', 'captivating',\n",
    "                 'california', 'develops', 'lucky', 'strength', 'studios', 'uncut',\n",
    "                 'quiet', 'stunning', 'paris', 'flight', 'gordon', 'underground',\n",
    "                 'builds', 'brilliantly', 'captured', 'mrs', 'covered', 'portrait',\n",
    "                 'delight', 'lovers', 'critical', 'intensity', 'melodrama', 'sentimental'])\n",
    "\n",
    "neg_words = set(['terrible', 'disappointing', 'waste', 'lowbudget', '310', 'darkness',\n",
    "                 'villains', 'disappointment', 'nonexistent', 'ridiculous', 'pointless',\n",
    "                 'joe', 'mess', 'ape', 'horrendous', 'forgettable', 'juvenile', 'garbage',\n",
    "                 'amateur', 'incomprehensible', 'remotely', 'toilet', 'zero', 'offended',\n",
    "                 'gotta', 'unwatchable', 'realized', 'unintentional', 'outer', 'cheated',\n",
    "                 'wasted', 'atrocious', 'ugly', 'promise', 'tarzan', 'awful', 'jane',\n",
    "                 'looked', 'law', 'worst', 'pretentious', 'subjected', 'secondly',\n",
    "                 'amazed', 'blatantly', 'riding', 'employed', 'woody', 'plague', 'incoherent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants to represent class labels\n",
    "ABSTAIN = -1\n",
    "POS = 1\n",
    "NEG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "negative_inflection_words = [\"but\", \"however\", \"otherwise\"]\n",
    "neg_adjs = set([\n",
    "    'bad', 'worst', 'horrible', 'terrible', 'stupid', 'boring', 'dreadful', 'disgust',\n",
    "    'disturbing', 'problem', 'disaster', 'a waste', 'not a fan'\n",
    "])\n",
    "pos_adjs = set([\n",
    "  'good', 'best', 'great', 'awesome', 'perfect', 'clever', 'charming',\n",
    "  'fascinating', 'pleasant', 'happy', 'hilarious', 'funny', 'wonderful', 'lovely'\n",
    "])\n",
    "\n",
    "@labeling_function()\n",
    "def good(x):\n",
    "    if re.search(r'not.{0,8}good', x.text.lower()):\n",
    "        return NEG\n",
    "    elif 'good' in x.text.lower():\n",
    "        return POS\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def bad(x):\n",
    "    if re.search(r'not.{0,8}bad', x.text.lower()):\n",
    "        return ABSTAIN\n",
    "    elif 'bad' in x.text.lower():\n",
    "        return NEG\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def pos_adj(x):\n",
    "    text = x.text.lower()\n",
    "\n",
    "    for word in pos_adjs:\n",
    "        char_index = text.find(word)\n",
    "        if char_index != -1:\n",
    "            substring = text[max(char_index - DISTANCE, 0):char_index]\n",
    "            if ('not' in substring) or ('n\\'t' in substring) :\n",
    "                continue\n",
    "            else:\n",
    "                return POS\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def neg_adj(x):\n",
    "    text = x.text.lower()\n",
    "    for word in neg_adjs:\n",
    "        char_index = text.find(word)\n",
    "        if char_index != -1:\n",
    "            substring = text[max(char_index - DISTANCE, 0):char_index]\n",
    "            if ('not' in substring) or ('n\\'t' in substring) :\n",
    "                continue\n",
    "            else:\n",
    "                return NEG\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def detect_pos_words_from_naive_bayes(x):\n",
    "    return POS if any(re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) \\\n",
    "                      for word in pos_words) else ABSTAIN\n",
    "    #return POS if any(word in x.text.lower() for word in pos_words) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def detect_neg_words_from_naive_bayes(x):\n",
    "    return NEG if any(re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) \\\n",
    "                      for word in neg_words) else ABSTAIN\n",
    "    #return NEG if any(word in x.text.lower() for word in neg_words) else ABSTAIN\n",
    "    \n",
    "@labeling_function()    \n",
    "def detect_pos_exclamation(x):\n",
    "    return POS if all(not re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) for word in neg_words) \\\n",
    "                    and '!' in x.text.lower() else ABSTAIN\n",
    "@labeling_function()                      \n",
    "def detect_neg_exclamation(x):\n",
    "    return NEG if all(not re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) for word in pos_words) \\\n",
    "                    and '!' in x.text.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def score_keywords(x):\n",
    "    text = x.text.lower()\n",
    "    pos_word_score = 1.0\n",
    "    neg_word_score = -1.0\n",
    "    score = 0\n",
    "    for word in pos_words:\n",
    "        if re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', text):\n",
    "            score += pos_word_score\n",
    "    for word in neg_words:\n",
    "        if re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', text):\n",
    "            score += neg_word_score\n",
    "    if score > 0:\n",
    "        return POS\n",
    "    elif score < 0:\n",
    "        return NEG\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying and tuning LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [neg_adj, \n",
    "       detect_pos_words_from_naive_bayes, detect_neg_words_from_naive_bayes,\n",
    "       detect_pos_exclamation, score_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:05<00:00, 151.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg_adj</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.44625</td>\n",
       "      <td>0.35125</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>251</td>\n",
       "      <td>106</td>\n",
       "      <td>0.703081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_words_from_naive_bayes</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.09250</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_neg_words_from_naive_bayes</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.37375</td>\n",
       "      <td>0.37375</td>\n",
       "      <td>0.03625</td>\n",
       "      <td>262</td>\n",
       "      <td>37</td>\n",
       "      <td>0.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_exclamation</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.19875</td>\n",
       "      <td>0.10875</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.761006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.58250</td>\n",
       "      <td>0.58250</td>\n",
       "      <td>0.07750</td>\n",
       "      <td>450</td>\n",
       "      <td>16</td>\n",
       "      <td>0.965665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "neg_adj                            0      [0]   0.44625   0.35125    0.11250   \n",
       "detect_pos_words_from_naive_bayes  1      [1]   0.26000   0.26000    0.09250   \n",
       "detect_neg_words_from_naive_bayes  2      [0]   0.37375   0.37375    0.03625   \n",
       "detect_pos_exclamation             3      [1]   0.19875   0.10875    0.05500   \n",
       "score_keywords                     4   [0, 1]   0.58250   0.58250    0.07750   \n",
       "\n",
       "                                   Correct  Incorrect  Emp. Acc.  \n",
       "neg_adj                                251        106   0.703081  \n",
       "detect_pos_words_from_naive_bayes      200          8   0.961538  \n",
       "detect_neg_words_from_naive_bayes      262         37   0.876254  \n",
       "detect_pos_exclamation                 121         38   0.761006  \n",
       "score_keywords                         450         16   0.965665  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_sdev = applier.apply(df=sdev_df)\n",
    "LFAnalysis(L=L_sdev, lfs=lfs).lf_summary(Y=np.asarray(sdev_df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24016/24016 [02:48<00:00, 142.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg_adj</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.445286</td>\n",
       "      <td>0.355846</td>\n",
       "      <td>0.162850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_words_from_naive_bayes</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.298842</td>\n",
       "      <td>0.298842</td>\n",
       "      <td>0.166805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_neg_words_from_naive_bayes</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.395944</td>\n",
       "      <td>0.395944</td>\n",
       "      <td>0.114424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_exclamation</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.192205</td>\n",
       "      <td>0.102931</td>\n",
       "      <td>0.059835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.520778</td>\n",
       "      <td>0.520778</td>\n",
       "      <td>0.107220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "neg_adj                            0      [0]  0.445286  0.355846   0.162850\n",
       "detect_pos_words_from_naive_bayes  1      [1]  0.298842  0.298842   0.166805\n",
       "detect_neg_words_from_naive_bayes  2      [0]  0.395944  0.395944   0.114424\n",
       "detect_pos_exclamation             3      [1]  0.192205  0.102931   0.059835\n",
       "score_keywords                     4   [0, 1]  0.520778  0.520778   0.107220"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = applier.apply(df=train_df)\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Majority Vote (baseline) on sdev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   87.5%\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "majority_acc = majority_model.score(L=L_sdev, Y=np.asarray(sdev_df[\"label\"]))[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7540888863202913}\n"
     ]
    }
   ],
   "source": [
    "# Attention: this part is pseudo-cheating!\n",
    "\n",
    "majority_model_test_perf = majority_model.score(L=L_train, Y=np.asarray(train_df[\"label\"]))\n",
    "print(majority_model_test_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Generative Model on train set and testing it on sdev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, lr=.001, log_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57494929, 0.54974223, 0.68197428, 0.42631496, 0.68492056])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8558282208588958}\n"
     ]
    }
   ],
   "source": [
    "label_model_perf = label_model.score(L=L_sdev, Y=np.asarray(sdev_df[\"label\"]))\n",
    "print(label_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7288012076414554}\n"
     ]
    }
   ],
   "source": [
    "# Attention: this part is pseudo-cheating!\n",
    "\n",
    "label_model_test_perf = label_model.score(L=L_train, Y=np.asarray(train_df[\"label\"]))\n",
    "print(label_model_test_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out unlabeled data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = label_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = model.predict_proba(L=L_train)\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=train_df, y=probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to start saying it has been a long time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought that Mukhsin has been wonderfully wr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all this was not a three hour movie -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I cant understand at all why so many Godzilla ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Hatred of a Minute\" is arguably one of the be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>I managed to catch a late night double feature...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>I agree with other users comments in that the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This movie is about this wimpy guy who decides...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I really enjoyed The 60's. Not being of that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>While on a vacation at the beach, red-haired b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19211 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I have to start saying it has been a long time...      1\n",
       "1      I thought that Mukhsin has been wonderfully wr...      1\n",
       "2      First of all this was not a three hour movie -...      1\n",
       "3      I cant understand at all why so many Godzilla ...      0\n",
       "5      \"Hatred of a Minute\" is arguably one of the be...      1\n",
       "...                                                  ...    ...\n",
       "24993  I managed to catch a late night double feature...      1\n",
       "24994  I agree with other users comments in that the ...      0\n",
       "24995  This movie is about this wimpy guy who decides...      1\n",
       "24997  I really enjoyed The 60's. Not being of that g...      1\n",
       "24998  While on a vacation at the beach, red-haired b...      0\n",
       "\n",
       "[19211 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8774"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.asarray(df_train_filtered['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = '../imdb-data/wd.csv'\n",
    "df_train_filtered.to_csv(export_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
