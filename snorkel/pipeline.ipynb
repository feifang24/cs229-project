{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into pandas\n",
    "def read_data(dir_path):\n",
    "    examples = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if not filename.endswith(\"txt\"):\n",
    "            continue\n",
    "        keys = filename.split(\".\")[0].split(\"_\")\n",
    "        assert len(keys) == 3\n",
    "        # keys is [id, label, review_score]. For now we are only interested in the label\n",
    "        label = keys[1]\n",
    "        with open(os.path.join(dir_path, filename)) as f:\n",
    "            text = f.read().strip().replace(\"<br />\", \" \")\n",
    "        examples.append([text, 1 if label == 'pos' else 0])\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's beyond my comprehension that so much rubb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bonjour Tristesse covers similar ground as 'Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have 2 words for you. Sean Bean. He is the o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big S isn't playing with taboos or forcing an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After seeing this film I complained to my loca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>A wonderful early musical film from Rene Clair...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>Nominated for the oscar \"worst script ever\" in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>A light-hearted comedy, Nothing shows us a wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>This movie has its ups and downs, but to me th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>**Warning! Spoilers Ahead!**  This short is pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     It's beyond my comprehension that so much rubb...      1\n",
       "1     Bonjour Tristesse covers similar ground as 'Th...      0\n",
       "2     I have 2 words for you. Sean Bean. He is the o...      0\n",
       "3     Big S isn't playing with taboos or forcing an ...      1\n",
       "4     After seeing this film I complained to my loca...      0\n",
       "...                                                 ...    ...\n",
       "1595  A wonderful early musical film from Rene Clair...      1\n",
       "1596  Nominated for the oscar \"worst script ever\" in...      0\n",
       "1597  A light-hearted comedy, Nothing shows us a wor...      1\n",
       "1598  This movie has its ups and downs, but to me th...      1\n",
       "1599  **Warning! Spoilers Ahead!**  This short is pa...      1\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SDEV_DIR = '../imdb-data/sd1600'\n",
    "sdev_data = read_data(SDEV_DIR)\n",
    "sdev_df = pd.DataFrame(sdev_data, columns=['text', 'label'])\n",
    "sdev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to start saying it has been a long time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought that Mukhsin has been wonderfully wr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all this was not a three hour movie -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I cant understand at all why so many Godzilla ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's beyond my comprehension that so much rubb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This movie is about this wimpy guy who decides...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>**Warning! Spoilers Ahead!**  This short is pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I really enjoyed The 60's. Not being of that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>While on a vacation at the beach, red-haired b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I saw \"El Mar\" yesterday and thought it to be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I have to start saying it has been a long time...      1\n",
       "1      I thought that Mukhsin has been wonderfully wr...      1\n",
       "2      First of all this was not a three hour movie -...      1\n",
       "3      I cant understand at all why so many Godzilla ...      0\n",
       "4      It's beyond my comprehension that so much rubb...      1\n",
       "...                                                  ...    ...\n",
       "24995  This movie is about this wimpy guy who decides...      1\n",
       "24996  **Warning! Spoilers Ahead!**  This short is pa...      1\n",
       "24997  I really enjoyed The 60's. Not being of that g...      1\n",
       "24998  While on a vacation at the beach, red-haired b...      0\n",
       "24999  I saw \"El Mar\" yesterday and thought it to be ...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIR = '../imdb-data/og'\n",
    "train_data = read_data(TRAIN_DIR)\n",
    "train_df = pd.DataFrame(train_data, columns=['text', 'label'])\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Naive Bayes on sdev set to generate keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_bayes.imdb import return_keywords_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary:  4342\n"
     ]
    }
   ],
   "source": [
    "all_words, most_pos_indices, most_neg_indices = return_keywords_indices(sdev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_KEYWORDS = 50\n",
    "\n",
    "top_pos_words = [all_words[ind] for ind in most_pos_indices[:NUM_KEYWORDS]]\n",
    "top_neg_words = [all_words[ind] for ind in most_neg_indices[:NUM_KEYWORDS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top pos words:\n",
      "['eddie', 'stunning', 'ship', 'wonderful', 'shakespeare', 'hank', 'henry', 'professional', 'finest', 'watson', 'con', 'fate', 'germany', 'crowd', 'mclaglen', 'guilt', 'groups', 'technology', 'tremendous', 'genuine', 'crafted', 'refreshing', 'wonderfully', 'sullivan', 'jackie', 'segment', 'poignant', 'fay', 'teaches', 'captivating', 'gorgeous', 'favorites', 'hitman', 'gothic', 'mafia', 'kungfu', 'hoffman', 'superbly', 'innocence', 'peace', 'arrives', 'ethan', 'sexuality', 'develops', 'stayed', 'expensive', 'immensely', 'perfection', 'classical', 'beaten']\n",
      "\n",
      "Top neg words:\n",
      "['pointless', 'poorly', 'laughable', 'waste', 'thugs', 'mediocre', 'remotely', '310', 'drags', 'amateurish', 'cabin', 'zombies', 'worst', 'accents', '1972', 'bergman', 'garbage', 'blatantly', '210', 'cardboard', 'terrible', 'awful', 'lowbudget', 'wasting', 'incomprehensible', 'boll', 'horrible', 'morality', 'infected', 'attack', 'meaningless', 'horrendous', 'forgettable', 'painfully', 'flag', 'idiotic', 'jumps', 'holiday', 'pack', 'unwatchable', 'choosing', 'unfunny', 'anne', 'zero', 'bland', 'moon', 'crap', 'zombie', 'blatant', 'incoherent']\n"
     ]
    }
   ],
   "source": [
    "print('Top pos words:')\n",
    "print(top_pos_words)\n",
    "print('\\nTop neg words:')\n",
    "print(top_neg_words)\n",
    "\n",
    "# Remember to post-process these by removing those words that are correlational but not causal, e.g. 'germany'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants to represent class labels\n",
    "ABSTAIN = -1\n",
    "POS = 1\n",
    "NEG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "negative_inflection_words = [\"but\", \"however\", \"otherwise\"]\n",
    "neg_adjs = set([\n",
    "    'bad', 'worst', 'horrible', 'terrible', 'stupid', 'boring', 'dreadful', 'disgust',\n",
    "    'disturbing', 'problem', 'disaster', 'a waste', 'not a fan'\n",
    "])\n",
    "pos_adjs = set([\n",
    "  'good', 'best', 'great', 'awesome', 'perfect', 'clever', 'charming',\n",
    "  'fascinating', 'pleasant', 'happy', 'hilarious', 'funny', 'wonderful', 'lovely'\n",
    "])\n",
    "\n",
    "pos_words = set(['stunning', 'wonderful', 'finest', 'professional', 'fate','crafted', \n",
    "                 'refreshing', 'tremendous', 'technology', 'genuine', 'wonderfully', 'favorites', \n",
    "                 'gorgeous', 'captivating', 'poignant', \n",
    "                 'segment', 'teaches', 'stayed', 'confronted', \n",
    "                 'perfection', 'peace', 'innocence', 'immensely', 'expensive',\n",
    "                 'develops', 'covered', 'arrives', 'superbly', 'beaten'])\n",
    "\n",
    "neg_words = set(['pointless', 'poorly', 'laughable', 'waste', 'mediocre',\n",
    "                 'remotely', 'amateurish', 'drags', 'worst',\n",
    "                 'blatantly', 'accents', 'garbage', 'terrible', \n",
    "                 'awful', 'wasting', 'lowbudget', 'horrible', 'infected',\n",
    "                 'incomprehensible', 'attack', 'unwatchable', 'painfully',\n",
    "                 'horrendous', 'forgettable', 'unfunny', 'pack', 'idiotic', \n",
    "                 'meaningless', 'zero', 'bland', 'crap', 'dire'])\n",
    "\n",
    "@labeling_function()\n",
    "def good(x):\n",
    "    if re.search(r'not.{0,8}good', x.text.lower()):\n",
    "        return NEG\n",
    "    elif 'good' in x.text.lower():\n",
    "        return POS\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def bad(x):\n",
    "    if re.search(r'not.{0,8}bad', x.text.lower()):\n",
    "        return ABSTAIN\n",
    "    elif 'bad' in x.text.lower():\n",
    "        return NEG\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def pos_adj(x):\n",
    "    text = x.text.lower()\n",
    "\n",
    "    for word in pos_adjs:\n",
    "        char_index = text.find(word)\n",
    "        if char_index != -1:\n",
    "            substring = text[max(char_index - DISTANCE, 0):char_index]\n",
    "            if ('not' in substring) or ('n\\'t' in substring) :\n",
    "                continue\n",
    "            else:\n",
    "                return POS\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def neg_adj(x):\n",
    "    text = x.text.lower()\n",
    "    for word in neg_adjs:\n",
    "        char_index = text.find(word)\n",
    "        if char_index != -1:\n",
    "            substring = text[max(char_index - DISTANCE, 0):char_index]\n",
    "            if ('not' in substring) or ('n\\'t' in substring) :\n",
    "                continue\n",
    "            else:\n",
    "                return NEG\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def detect_pos_words_from_naive_bayes(x):\n",
    "    return POS if any(re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) \\\n",
    "                      for word in pos_words) else ABSTAIN\n",
    "    #return POS if any(word in x.text.lower() for word in pos_words) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def detect_neg_words_from_naive_bayes(x):\n",
    "    return NEG if any(re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) \\\n",
    "                      for word in neg_words) else ABSTAIN\n",
    "    #return NEG if any(word in x.text.lower() for word in neg_words) else ABSTAIN\n",
    "    \n",
    "@labeling_function()    \n",
    "def detect_pos_exclamation(x):\n",
    "    return POS if all(not re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) for word in neg_words) \\\n",
    "                    and '!' in x.text.lower() else ABSTAIN\n",
    "@labeling_function()                      \n",
    "def detect_neg_exclamation(x):\n",
    "    return NEG if all(not re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', x.text.lower()) for word in pos_words) \\\n",
    "                    and '!' in x.text.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def score_keywords(x):\n",
    "    text = x.text.lower()\n",
    "    pos_word_score = 1.0\n",
    "    neg_word_score = -1.0\n",
    "    score = 0\n",
    "    for word in pos_words:\n",
    "        if re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', text):\n",
    "            score += pos_word_score\n",
    "    for word in neg_words:\n",
    "        if re.search(r'[.!?\\-\\s]' + word + r'[.!?\\-\\s]', text):\n",
    "            score += neg_word_score\n",
    "    if score > 0:\n",
    "        return POS\n",
    "    elif score < 0:\n",
    "        return NEG\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying and tuning LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [neg_adj, \n",
    "       detect_pos_words_from_naive_bayes, detect_neg_words_from_naive_bayes,\n",
    "       detect_pos_exclamation, score_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:07<00:00, 221.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg_adj</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.451875</td>\n",
       "      <td>0.329375</td>\n",
       "      <td>0.093125</td>\n",
       "      <td>508</td>\n",
       "      <td>215</td>\n",
       "      <td>0.702628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_words_from_naive_bayes</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>0.175625</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>254</td>\n",
       "      <td>27</td>\n",
       "      <td>0.903915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_neg_words_from_naive_bayes</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>456</td>\n",
       "      <td>59</td>\n",
       "      <td>0.885437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_exclamation</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.198125</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>241</td>\n",
       "      <td>76</td>\n",
       "      <td>0.760252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.460625</td>\n",
       "      <td>0.460625</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>686</td>\n",
       "      <td>51</td>\n",
       "      <td>0.930801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "neg_adj                            0      [0]  0.451875  0.329375   0.093125   \n",
       "detect_pos_words_from_naive_bayes  1      [1]  0.175625  0.175625   0.065625   \n",
       "detect_neg_words_from_naive_bayes  2      [0]  0.321875  0.321875   0.024375   \n",
       "detect_pos_exclamation             3      [1]  0.198125  0.085000   0.051875   \n",
       "score_keywords                     4   [0, 1]  0.460625  0.460625   0.053125   \n",
       "\n",
       "                                   Correct  Incorrect  Emp. Acc.  \n",
       "neg_adj                                508        215   0.702628  \n",
       "detect_pos_words_from_naive_bayes      254         27   0.903915  \n",
       "detect_neg_words_from_naive_bayes      456         59   0.885437  \n",
       "detect_pos_exclamation                 241         76   0.760252  \n",
       "score_keywords                         686         51   0.930801  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_sdev = applier.apply(df=sdev_df)\n",
    "LFAnalysis(L=L_sdev, lfs=lfs).lf_summary(Y=np.asarray(sdev_df[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [02:01<00:00, 205.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg_adj</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.44492</td>\n",
       "      <td>0.33788</td>\n",
       "      <td>0.12612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_words_from_naive_bayes</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.19572</td>\n",
       "      <td>0.19572</td>\n",
       "      <td>0.09172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_neg_words_from_naive_bayes</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.32976</td>\n",
       "      <td>0.32976</td>\n",
       "      <td>0.05192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detect_pos_exclamation</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.21528</td>\n",
       "      <td>0.10012</td>\n",
       "      <td>0.06520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.44384</td>\n",
       "      <td>0.44384</td>\n",
       "      <td>0.06200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "neg_adj                            0      [0]   0.44492   0.33788    0.12612\n",
       "detect_pos_words_from_naive_bayes  1      [1]   0.19572   0.19572    0.09172\n",
       "detect_neg_words_from_naive_bayes  2      [0]   0.32976   0.32976    0.05192\n",
       "detect_pos_exclamation             3      [1]   0.21528   0.10012    0.06520\n",
       "score_keywords                     4   [0, 1]   0.44384   0.44384    0.06200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = applier.apply(df=train_df)\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Majority Vote (baseline) on sdev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   83.0%\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "majority_acc = majority_model.score(L=L_sdev, Y=np.asarray(sdev_df[\"label\"]))[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   77.6%\n"
     ]
    }
   ],
   "source": [
    "majority_model_test_acc = majority_model.score(L=L_train, Y=np.asarray(train_df[\"label\"]))[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_model_test_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Generative Model on train set and testing it on sdev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=5, lr=0.001, log_freq=100, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     80.9%\n"
     ]
    }
   ],
   "source": [
    "label_model_acc = label_model.score(L=L_sdev, Y=np.asarray(sdev_df[\"label\"]))[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     75.6%\n"
     ]
    }
   ],
   "source": [
    "label_model_test_acc = label_model.score(L=L_train, Y=np.asarray(train_df[\"label\"]))[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_test_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
